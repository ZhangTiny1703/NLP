1.数据来源
  各种网站爬虫

2.数据清洗
  清洗内容：
    多余的空格
    不正规的符号
    多余的字符、英文
  清洗方法：
    正则化
    切分
    好坏语句判断

3.数据处理
  文本 -> 自然句(正则) -> 自然句分词(asnj/hanlp) -> 向量(sent2vec) -> 句子(faiss)
  
 4.数据模型的保存
  (1).使用pickle来保存模型            
  (2).生成pkl格式                    
  (3).利用pkl格式进行数据的训练
              
  
